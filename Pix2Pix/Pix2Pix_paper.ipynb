{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dad3e780",
   "metadata": {},
   "source": [
    "# Image-to-Image Translation with Conditional Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d0134c",
   "metadata": {},
   "source": [
    "## Abstract  \n",
    "- 본 논문에서는 image-to-imgae 변환에 다양하게 쓰일 solution으로 conditional adversarial network이라는 것을 연구함  \n",
    "- 이 네트워크는 input image에서 output image로의 mapping을 학습할 뿐만 아니라 이를 훈련시키기 위한 loss 함수도 학습함  \n",
    "- 이 접근 방식이 label map에서 사진을 합성하고 object를 재구성하고 이미지를 컬러화하는데 효과적이라는 것을 보여줌  \n",
    "\n",
    "- 이미지 복원, 흑백을 컬러로 변경 등 다양한 문제들에 있어 따로 연구가 되어옴  \n",
    "- 본 논문에서는 이러한 변환 문제들을 한 번에 해결할 수 있는 어떤 framework를 개발하는 것을 목표로 함\n",
    "\n",
    "- 실제로도 Pix2Pix가 다양한 곳에 적용을 할 수 있다는 것을 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe5469d",
   "metadata": {},
   "source": [
    "## Introduction  \n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdJYwRS%2Fbtq2tstcz9a%2Fm6k7kBHzXJwavzoHBRgNb0%2Fimg.png\">  \n",
    "\n",
    "- image-to-image translation을 정의  \n",
    "- CV 분야에서는 각 목적에 맞는 다양한 모델들이 따로 연구가 진행됨    \n",
    "- 그러나 이 논문에서는 다양한 목적에 광범위하게 쓸 수 있는 하나의 framework를 개발  \n",
    "- 대표적으로 CNN이 존재\n",
    "- 보통 CNN은 loss를 최소화하는 방향으로 학습을 하지만 더 효과적으로 loss를 더 줄이기 위한 노력이 필요  \n",
    "- 단순히 output과 label pixel의 유클리디안 거리를 최소화하라는 것은 흐릿한 이미지를 생성하게 됨  \n",
    "- GAN의 경우 output image가 진짜인지 가짜인지 분류를 하며 loss를 줄여나감  \n",
    "- 블러 이미지의 경우 명확하게 가짜 이미지이기 때문에 discriminator 모델이 학습이 금방 됨  \n",
    "- 그래서 이 논문에서는 conditional GAN에 대해 다룸  \n",
    "- input image를 조건화하고 동일한 사이즈의 output을 출력시키는 image-to-image 변형 작업에 적합함  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917edb9d",
   "metadata": {},
   "source": [
    "## Method  \n",
    "- GAN은 랜덤 노이즈를 가지고 이미지를 생성  \n",
    "- 반면 conditional GAN은 이미지 $x$와 랜덤 노이즈 $z$를 가지고 이미지를 생성  \n",
    "### Object  \n",
    "- predict한 이미지와 실제 이미지의 차이를 줄여주는 loss function으로 L1 loss function을 사용  \n",
    "- L2보다는 L1이 blurring한 이미지가 덜 생성됨\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FQds1f%2Fbtq2lBZRt7L%2FdvmgjQl33kVtvWgkGHRbP1%2Fimg.png\">    \n",
    "\n",
    "- 그리고 cGAN의 loss function을 사용  \n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCShiT%2Fbtq2lA7GCjF%2FSnapcXpQvDmzm3mbJ61P1k%2Fimg.png\">  \n",
    "\n",
    "- 따라서 우리가 정의한 loss function은 다음과 같다  \n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb8FF06%2Fbtq2plIJRRN%2F8VvUjrnj1C3OrWxBvLXEj1%2Fimg.png\">  \n",
    "\n",
    "- 이때 $\\lambda$는 두 L1 loss의 가중치\n",
    "\n",
    "- 다음 그림을 통해 L1 loss를 사용함으로 인해 이미지가 어떻게 생성되는지 볼 수 있다  \n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZvsrg%2Fbtq2npq6iYk%2F2L5z3p9LaOyUQXHGSYfgmK%2Fimg.webp\">    \n",
    "\n",
    "### Network architectures  \n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbED3U9%2FbtqX0pPx7ir%2FPumsoQ91c0zHrwt1pTwbT1%2Fimg.png\">  \n",
    "\n",
    "#### Generator with skips\n",
    "- Pix2Pix는 output이 input과 같은 해상도를 가져야하는 만큼 복원력도 중요함  \n",
    "- 그래서 Generator 모델에 upsampling 기법을 이용함  \n",
    "- 이때 AutoEncoder 구조를 적용하면 좋은 해상도를 기대하기 어려움  \n",
    "- 그래서 중간에 feature map을 결합해주는 skip connection 구조를 사용함  \n",
    "- 다음 그림을 통해 AutoEncoder와 U-Net의 차이를 볼 수 있음  \n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbtwQsq%2Fbtq2uc45xI0%2FereZaByLKZAXWXlkfS51qK%2Fimg.png\">\n",
    "\n",
    "#### PatchGAN  \n",
    "- 모델의 high-frequency를 위해 이미지 패치를 사용함  \n",
    "- 전체 이미지에 대해 훈련을 시키면 학습 속도가 느리다는 문제가 생김  \n",
    "- 그래서 patch별로 학습을 진행함  \n",
    "- 이는 학습 속도도 빠르며 고퀄리티의 성능을 보여줌  \n",
    "- 다음 그림을 통해 patch 사이즈 별로 학습 성능을 볼 수 있다\n",
    "\n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbl6ASA%2FbtqX81NDc4i%2F4tfKw0Z8KULkynNNFn5bAK%2Fimg.png\">  \n",
    "\n",
    "- 위의 그림을 보자  \n",
    "- 70x70의 patch size가 가장 좋은 성능을 보이고 있다  \n",
    "- 또한 286x286 patch size도 좋은 성능을 보이고 있지만 학습할 파라미터의 수가 더 많다는 단점이 존재함  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e557905b",
   "metadata": {},
   "source": [
    "### 모델 출력 이미지 예시  \n",
    "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F8yeGg%2FbtqXXVu7Nbi%2Fbp1xySj14hotFJBZ6wukZk%2Fimg.png\">  \n",
    "\n",
    "- 지도 사진을 위성 사진으로 또한 위성 사진을 지도 사진으로 변환을 해줌  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
