{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4803b321",
   "metadata": {},
   "source": [
    "# DCGAN (Deep Convolutional Generative Adversarial Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f3afa1",
   "metadata": {},
   "source": [
    "## Abstract  \n",
    "- In recent years, supervised learning with convolutional networks has seen huge adoption in CV applications.  \n",
    "- Comparatively, unsupervised learning with CNNs has received less attention.  \n",
    "- In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning.  \n",
    "- So, we introduce deep convolutional generative adversarial networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622a814",
   "metadata": {},
   "source": [
    "## Approach and Model Architecture  \n",
    "<img src = \"https://media.vlpt.us/images/changdaeoh/post/6549f9c6-98ae-4d8c-a4ae-dbb7515df6c0/image.png\">\n",
    "\n",
    "- Core to out approach is adopting and modifying three recently demonstrated changes to CNN architectures.  \n",
    "\n",
    "**First**  \n",
    "- This is the all convolutional net which replaces pooling layer with strided convolutions, allowing the network to learn its own spatial downsampling.  \n",
    "- We use this approach in our generator.  \n",
    "\n",
    "**Second**  \n",
    "- This is the trend towards eliminating fully connected layers.  \n",
    "- A middle ground of directly connecting the highest convolutional features to the input and output respectively of the generator and discriminator worked well.  \n",
    "- The first layer of the GAN, which takes a uniform noise distribution Z as input.  \n",
    "- And in the next layer, this is transformed 4-dimensional tensor.  \n",
    "- For the discriminator, the last convolution layer is flattened and then fed into a single sigmoid output.  \n",
    "\n",
    "**Third**  \n",
    "- This is Batch Normalization which stabilizes learning by normalizing the input to each unit to have zero mean and unit variance.  \n",
    "- This helps deal with training problems that arise due to poor initialization and helps gradient flow in deeper models.  \n",
    "- However, we applied batchnorm to all layers except the last layers.  \n",
    "\n",
    "  \n",
    "- The ReLU activation is used in the generator with the exception of the output layer which use the Tanh function.  \n",
    "- We observed that using a bounded activation allowed the model to learn more quickly to sturate and cover the color space of the training distribution.  \n",
    "- Within the discriminator we found the leaky ReLU to work well, especially for higher resolution modeling.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7720e07f",
   "metadata": {},
   "source": [
    "## Details of Adversarial Training  \n",
    "- No pre-processing was applied to training images besides scaling to the range of the tanh activation function $\\left[-1,1\\right]$.  \n",
    "- All models were trained with mini-batch SGD with a mini-batch size of 128.  \n",
    "- All weights were initialized from a zero-centered Normal distribution with sd 0.02.  \n",
    "- In the LeakyReLU, the slope is 0.2 in all models.  \n",
    "- And we used the Adam optimizer with using learning rate 0.0002.  \n",
    "- Additionally, we found leaving the momentum term $\\beta_1$ at the suggested value of 0.9 resulted in training oscillation and instability while reducing it to 0.5 helped stabilize training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf61c77",
   "metadata": {},
   "source": [
    "## LSUN  \n",
    "<img src = \"https://media.vlpt.us/images/changdaeoh/post/44489278-85c4-4955-b646-1ed2b641d3b4/image.png\">  \n",
    "<img src = \"https://media.vlpt.us/images/changdaeoh/post/37b645f7-9959-4d07-ba69-79a73e6dda15/image.png\">  \n",
    "\n",
    "- To further decrease the likelihood of the generator memorizing input examples (above figure) we perform a simple image de-duplication process.  \n",
    "- We used de-noising dropout regularized ReLU autoencoder on 32x32 downsampled center-crops of training examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7461d048",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
